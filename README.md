# github-attention
> This project includes several ##attention modules## , those were used to "pay some attention to more messages".
> All about those modules with the same input and output size, such as B C H W.
